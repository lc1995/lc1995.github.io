<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Reinforcement Learning," />










<meta name="description" content="Today I begin the study of Reinforcement Learning, which is one of the interesting research field i would like to study. These few years we see the research tea">
<meta name="keywords" content="Reinforcement Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Reinforcement Learning Introduction">
<meta property="og:url" content="http://lc1995.github.io/2018/04/20/Reinforcement-Learning-Introduction/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Today I begin the study of Reinforcement Learning, which is one of the interesting research field i would like to study. These few years we see the research team DeepMind has done a lot in this field,">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://lc1995.github.io/images/f1.png">
<meta property="og:updated_time" content="2018-04-25T16:39:11.843Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reinforcement Learning Introduction">
<meta name="twitter:description" content="Today I begin the study of Reinforcement Learning, which is one of the interesting research field i would like to study. These few years we see the research team DeepMind has done a lot in this field,">
<meta name="twitter:image" content="http://lc1995.github.io/images/f1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://lc1995.github.io/2018/04/20/Reinforcement-Learning-Introduction/"/>





  <title>Reinforcement Learning Introduction | Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://lc1995.github.io/2018/04/20/Reinforcement-Learning-Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chang Lin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Reinforcement Learning Introduction</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-20T23:37:28+02:00">
                2018-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reinforcement-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Reinforcement Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/20/Reinforcement-Learning-Introduction/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/2018/04/20/Reinforcement-Learning-Introduction/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Today I begin the study of <strong>Reinforcement Learning</strong>, which is one of the interesting research field i would like to study. These few years we see the research team DeepMind has done a lot in this field, and made numbers of achievements. We see AlphaGo in GO, we see AlphaZero in multiple chess games, we also see DeepMind tried to create a human-like ai in the game Starcraft II. Although finally they didn’t successfully create an ai that behaves like human, maybe due to the limitation of current algorithms, ai architecture or other reasons. However, they also discover many interesting ai behaviors, like ai will lift the base on the sky, in order to avoid enemies’ attack. They are also some already made human-like ai in games like Super Mario using Reinforcement Learning.</p>
<p>For me, I am expecting one day i can create an immersive and powerful ai in some RPG games, like <em>The Elder of Scrolls : Skyrim</em> or <em>Sim</em> series. I am also expecting one day the NPC in games can be like a human or more crazy, we cannot even distinguish between the guy facing you is a real person or a NPC. That’s really cool!</p>
<p>Also, I am always thinking that, a good ai can be composed of some basic general principles, instead of combination of a vast number of special purpose tricks, procedures and heuristics. In these days, most of the ai is realized by finite state machine and behavior trees. I am not saying they are not good technologies, in truth they are very powerful in designing a good ai. But that’s not enough for an ai to behave like a human. We can try making a more complex ai, but that’s just adding more characteristics to an ai. We need some way to let ai have the ability to learn something, in the guidance of some general principles. That’s why i am interested in this field.</p>
<p>In the remaining of this article, I will write down what I learn and what I think after reading the book &lt; Reinforcement Learning : An Introduction &gt; by Richard S. Sutton and Andrew G. Barto. </p>
<a id="more"></a>
<h1 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h1><blockquote>
<p>Reinforcement learning is learning what to do — how to map situations to actions — so as to maximize a numerical reward signal.</p>
</blockquote>
<p>Trial-and-error and delayed reward are the two most important distinguishing features of reinforcement learning.</p>
<h2 id="Trial-And-Error"><a href="#Trial-And-Error" class="headerlink" title="Trial-And-Error"></a>Trial-And-Error</h2><p>The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them.</p>
<h2 id="Delayed-Reward"><a href="#Delayed-Reward" class="headerlink" title="Delayed Reward"></a>Delayed Reward</h2><p>In the most interesting and challenging cases, actions may affect not only the immediate reward but also the next situation and, through that, all subsequent rewards.</p>
<h2 id="Exploration-and-Exploitation"><a href="#Exploration-and-Exploitation" class="headerlink" title="Exploration and Exploitation"></a>Exploration and Exploitation</h2><p>The agent has to exploit what it has already experienced in order to obtain reward, but it also has to explore in order to make better action selections in the future.</p>
<p>In all, the agent must try a variety of actions and <strong>progressively</strong> favor those that appear to be best.</p>
<h1 id="Elements"><a href="#Elements" class="headerlink" title="Elements"></a>Elements</h1><p>Reinforcement learning has the following four main elements.</p>
<h2 id="Policy"><a href="#Policy" class="headerlink" title="Policy"></a>Policy</h2><blockquote>
<p>A policy defines the learning agent’s way of behaving at a given time.</p>
</blockquote>
<p>A policy is like a mapping from state(environment) to action(decision) —  In each specific case of state, which action we decide to choose. That’s also what reinforcement learning learns, to select the best policy in the policy space.</p>
<h2 id="Reward-Signal"><a href="#Reward-Signal" class="headerlink" title="Reward Signal"></a>Reward Signal</h2><blockquote>
<p>A reward signal defines the goal in a reinforcement learning problem.</p>
</blockquote>
<p>Reward helps us to decide whether a policy is good or not, or let’s say to estimate an action in current state.</p>
<h2 id="Value-Function"><a href="#Value-Function" class="headerlink" title="Value Function"></a>Value Function</h2><blockquote>
<p>A value function specifies what is good in the long run.</p>
</blockquote>
<p>Different from reward, a value of a state will take account of all rewards over the future, starting from the current state, to dicide whether a policy is good or not in the future. In fact, the most important component of almost all reinforcement learning algorithms we consider is a method for efficiently estimating values.</p>
<h2 id="Model-of-Environment"><a href="#Model-of-Environment" class="headerlink" title="Model of Environment"></a>Model of Environment</h2><blockquote>
<p>A model of environment allows inferences to be made about how the environment will behave.</p>
</blockquote>
<p>Here we don’t just look at the current state and reward, but also take account of the environment, predict the environment response to the policy we adopt. By this mean, we can obtain the next state and also the next reward, while in this case we don’t need trial-and-error.</p>
<h1 id="Difference-with-Evolutionary-Method"><a href="#Difference-with-Evolutionary-Method" class="headerlink" title="Difference with Evolutionary Method"></a>Difference with Evolutionary Method</h1><p>Evolutionary methods such as genetic algorithm, genetic programming, simulated annealing and other optimization methods have been used to approach reinforcement learning without using value function. Each time they select a policy from the policy state, use it to interact with environment multiple times, and finally obtain one with the best reward.</p>
<p>However, evolutionary method ignores much of the useful information during the process, and only care about the final result(winning posibility). This may sometimes cause misleading.</p>
<h1 id="An-Example-Tic-Tac-Toe"><a href="#An-Example-Tic-Tac-Toe" class="headerlink" title="An Example: Tic-Tac-Toe"></a>An Example: Tic-Tac-Toe</h1><p>Traditionary solution:</p>
<ul>
<li>Minimax</li>
<li>Dynamic Programming</li>
<li>Evolutionary Method</li>
</ul>
<p>In reinforcement learning, we use the rule of “temporal difference learning method”.</p>
<p><img src="/images/f1.png" alt=""></p>
<p>While we are playing, we change the values of the states in which we find ourselves during the game. We attempt to make them more accurate estimates of the probabilities of winning. To do this, we need to update the previous state every time we select an optimal action and go into a new state.</p>
<p>If the step-size param- eter is reduced properly over time, then this method converges, for any fixed opponent, to the true probabilities of winning from each state given optimal play by our player.</p>
<h1 id="Some-Tips"><a href="#Some-Tips" class="headerlink" title="Some Tips"></a>Some Tips</h1><ol>
<li>We can teach the agent some prior knowledge to improve search efficiency.</li>
<li>Behaviors(Actions) can be continuous instead of descrete, also reward function can be.</li>
<li>State set can be large or even infinity. How well a reinforcement learning system can work in problems with such large state sets is intimately tied to how appropriately it can generalize from past experience. Here supervised learning, neural network and deep learning may help.</li>
<li>A model of environment(model-based system) may help to improve the learning effect. It depends on the difficulty to obtain (or learn) a good environment model which is reasonably accurate to be useful. </li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Reinforcement-Learning/" rel="tag"># Reinforcement Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/19/Unity-Customize-Editor/" rel="next" title="Unity Customize Editor">
                <i class="fa fa-chevron-left"></i> Unity Customize Editor
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/04/28/Reinforcement-Learning-Chapter-2/" rel="prev" title="Reinforcement Learning Chapter 2">
                Reinforcement Learning Chapter 2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Chang Lin</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/lc1995" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:lucianolin1995@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Definition"><span class="nav-number">1.</span> <span class="nav-text">Definition</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Trial-And-Error"><span class="nav-number">1.1.</span> <span class="nav-text">Trial-And-Error</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Delayed-Reward"><span class="nav-number">1.2.</span> <span class="nav-text">Delayed Reward</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Exploration-and-Exploitation"><span class="nav-number">1.3.</span> <span class="nav-text">Exploration and Exploitation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Elements"><span class="nav-number">2.</span> <span class="nav-text">Elements</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Policy"><span class="nav-number">2.1.</span> <span class="nav-text">Policy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reward-Signal"><span class="nav-number">2.2.</span> <span class="nav-text">Reward Signal</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Value-Function"><span class="nav-number">2.3.</span> <span class="nav-text">Value Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model-of-Environment"><span class="nav-number">2.4.</span> <span class="nav-text">Model of Environment</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Difference-with-Evolutionary-Method"><span class="nav-number">3.</span> <span class="nav-text">Difference with Evolutionary Method</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#An-Example-Tic-Tac-Toe"><span class="nav-number">4.</span> <span class="nav-text">An Example: Tic-Tac-Toe</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Some-Tips"><span class="nav-number">5.</span> <span class="nav-text">Some Tips</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chang Lin</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  







<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: window.location.pathname, 
            owner: 'lc1995',
            repo: 'lc1995.github.io',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: 'f8c2095d8dc16bb768802ae8cbd0e7917eb7cb4a',
            
                client_id: 'ce5223552f85fd516b62'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    







  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
